{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### unfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53972159/how-does-pytorchs-fold-and-unfold-work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.Unfold(  \n",
    "    kernel_size,  \n",
    "    dilation=1, padding=0, stride=1)  \n",
    "  \n",
    "* kernel_size (int or tuple) – the size of the sliding blocks  \n",
    "  \n",
    "  \n",
    "* stride (int or tuple, optional) – the stride of the sliding blocks in the input spatial dimensions. Default: 1\n",
    "* padding (int or tuple, optional) – implicit zero padding to be added on both sides of input. Default: 0\n",
    "* dilation (int or tuple, optional) – a parameter that controls the stride of elements within the neighborhood. Default: 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. unfold is a making window (kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold = nn.Unfold(kernel_size=(2, 3)) # 사이즈 : 2x3, 6개의 요소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5223, -0.2952,  0.3551,  0.2865],\n",
       "          [ 0.0066, -0.6348, -1.2648, -0.3411],\n",
       "          [ 0.1455,  0.6420, -1.2262,  0.6646]],\n",
       "\n",
       "         [[ 0.5227,  0.0675,  2.2939, -0.9430],\n",
       "          [ 1.7125,  0.7122, -0.6256,  1.7609],\n",
       "          [ 0.6527,  2.1585, -1.9699, -1.4661]],\n",
       "\n",
       "         [[-0.4349,  0.4933, -1.7456,  0.0696],\n",
       "          [-0.6547,  0.1629, -0.0294,  1.2622],\n",
       "          [-0.2090, -0.0254, -0.5135, -1.0149]],\n",
       "\n",
       "         [[-1.9260,  1.1769, -1.1372, -0.2015],\n",
       "          [ 0.6423, -0.6941, -1.6763,  0.9137],\n",
       "          [ 1.8009,  0.7254, -0.0135,  0.1131]],\n",
       "\n",
       "         [[-1.1822, -1.4841,  0.5706, -0.2356],\n",
       "          [ 0.3818,  0.6736,  0.5526,  0.1307],\n",
       "          [-1.5265,  0.1199, -1.3868,  1.5758]]],\n",
       "\n",
       "\n",
       "        [[[-1.0304, -0.1849,  0.5200,  0.8863],\n",
       "          [ 0.4583,  0.7302, -0.2049, -0.5554],\n",
       "          [-1.2646,  0.1102, -0.3027,  0.1845]],\n",
       "\n",
       "         [[ 0.4840,  0.8333, -0.6412,  0.1023],\n",
       "          [ 1.3409,  1.4884, -0.6821, -1.3943],\n",
       "          [-0.3098,  1.0579,  0.9946, -0.2173]],\n",
       "\n",
       "         [[-1.6077, -0.1820,  0.5209,  0.5634],\n",
       "          [ 3.1501,  1.1375, -0.6137, -1.2171],\n",
       "          [-0.2776,  1.3041,  0.0106,  0.1619]],\n",
       "\n",
       "         [[ 0.3162,  0.1911, -1.6910,  0.7188],\n",
       "          [ 0.4825,  1.7309, -0.7692, -0.6060],\n",
       "          [-0.0463, -0.8806, -1.2019, -0.6046]],\n",
       "\n",
       "         [[-1.0030, -0.0489, -1.3904, -1.1508],\n",
       "          [-0.4539,  0.9174,  0.7998,  1.1468],\n",
       "          [-0.8801,  2.0009,  0.8760,  1.2482]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 5, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30, 4])\n",
      "tensor([[[-1.5223, -0.2952,  0.0066, -0.6348],\n",
      "         [-0.2952,  0.3551, -0.6348, -1.2648],\n",
      "         [ 0.3551,  0.2865, -1.2648, -0.3411],\n",
      "         [ 0.0066, -0.6348,  0.1455,  0.6420],\n",
      "         [-0.6348, -1.2648,  0.6420, -1.2262],\n",
      "         [-1.2648, -0.3411, -1.2262,  0.6646],\n",
      "         [ 0.5227,  0.0675,  1.7125,  0.7122],\n",
      "         [ 0.0675,  2.2939,  0.7122, -0.6256],\n",
      "         [ 2.2939, -0.9430, -0.6256,  1.7609],\n",
      "         [ 1.7125,  0.7122,  0.6527,  2.1585],\n",
      "         [ 0.7122, -0.6256,  2.1585, -1.9699],\n",
      "         [-0.6256,  1.7609, -1.9699, -1.4661],\n",
      "         [-0.4349,  0.4933, -0.6547,  0.1629],\n",
      "         [ 0.4933, -1.7456,  0.1629, -0.0294],\n",
      "         [-1.7456,  0.0696, -0.0294,  1.2622],\n",
      "         [-0.6547,  0.1629, -0.2090, -0.0254],\n",
      "         [ 0.1629, -0.0294, -0.0254, -0.5135],\n",
      "         [-0.0294,  1.2622, -0.5135, -1.0149],\n",
      "         [-1.9260,  1.1769,  0.6423, -0.6941],\n",
      "         [ 1.1769, -1.1372, -0.6941, -1.6763],\n",
      "         [-1.1372, -0.2015, -1.6763,  0.9137],\n",
      "         [ 0.6423, -0.6941,  1.8009,  0.7254],\n",
      "         [-0.6941, -1.6763,  0.7254, -0.0135],\n",
      "         [-1.6763,  0.9137, -0.0135,  0.1131],\n",
      "         [-1.1822, -1.4841,  0.3818,  0.6736],\n",
      "         [-1.4841,  0.5706,  0.6736,  0.5526],\n",
      "         [ 0.5706, -0.2356,  0.5526,  0.1307],\n",
      "         [ 0.3818,  0.6736, -1.5265,  0.1199],\n",
      "         [ 0.6736,  0.5526,  0.1199, -1.3868],\n",
      "         [ 0.5526,  0.1307, -1.3868,  1.5758]],\n",
      "\n",
      "        [[-1.0304, -0.1849,  0.4583,  0.7302],\n",
      "         [-0.1849,  0.5200,  0.7302, -0.2049],\n",
      "         [ 0.5200,  0.8863, -0.2049, -0.5554],\n",
      "         [ 0.4583,  0.7302, -1.2646,  0.1102],\n",
      "         [ 0.7302, -0.2049,  0.1102, -0.3027],\n",
      "         [-0.2049, -0.5554, -0.3027,  0.1845],\n",
      "         [ 0.4840,  0.8333,  1.3409,  1.4884],\n",
      "         [ 0.8333, -0.6412,  1.4884, -0.6821],\n",
      "         [-0.6412,  0.1023, -0.6821, -1.3943],\n",
      "         [ 1.3409,  1.4884, -0.3098,  1.0579],\n",
      "         [ 1.4884, -0.6821,  1.0579,  0.9946],\n",
      "         [-0.6821, -1.3943,  0.9946, -0.2173],\n",
      "         [-1.6077, -0.1820,  3.1501,  1.1375],\n",
      "         [-0.1820,  0.5209,  1.1375, -0.6137],\n",
      "         [ 0.5209,  0.5634, -0.6137, -1.2171],\n",
      "         [ 3.1501,  1.1375, -0.2776,  1.3041],\n",
      "         [ 1.1375, -0.6137,  1.3041,  0.0106],\n",
      "         [-0.6137, -1.2171,  0.0106,  0.1619],\n",
      "         [ 0.3162,  0.1911,  0.4825,  1.7309],\n",
      "         [ 0.1911, -1.6910,  1.7309, -0.7692],\n",
      "         [-1.6910,  0.7188, -0.7692, -0.6060],\n",
      "         [ 0.4825,  1.7309, -0.0463, -0.8806],\n",
      "         [ 1.7309, -0.7692, -0.8806, -1.2019],\n",
      "         [-0.7692, -0.6060, -1.2019, -0.6046],\n",
      "         [-1.0030, -0.0489, -0.4539,  0.9174],\n",
      "         [-0.0489, -1.3904,  0.9174,  0.7998],\n",
      "         [-1.3904, -1.1508,  0.7998,  1.1468],\n",
      "         [-0.4539,  0.9174, -0.8801,  2.0009],\n",
      "         [ 0.9174,  0.7998,  2.0009,  0.8760],\n",
      "         [ 0.7998,  1.1468,  0.8760,  1.2482]]])\n"
     ]
    }
   ],
   "source": [
    "output = unfold(x)\n",
    "print(output.shape) \n",
    "# 6개 요소 x 5 채널 = 30 요소. 그리고 kernel이 (3,4) feature map 에 매칭되는 게 4번.\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. convolution is equivalent with unfold + matrix multiplication + fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(1, 3, 10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(2, 3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 56])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n",
    "inp_unf.shape # 20 x 3 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 60])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_unf.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 60])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.view(w.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.view(w.size(0), -1).t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 56])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out_unf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fold in module torch.nn.functional:\n",
      "\n",
      "fold(input, output_size, kernel_size, dilation=1, padding=0, stride=1)\n",
      "    Combines an array of sliding local blocks into a large containing\n",
      "    tensor.\n",
      "    \n",
      "    .. warning::\n",
      "        Currently, only 4-D output tensors (batched image-like tensors) are\n",
      "        supported.\n",
      "    \n",
      "    See :class:`torch.nn.Fold` for details\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn.functional.fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 7, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 7, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = torch.nn.functional.conv2d(inp, w)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
