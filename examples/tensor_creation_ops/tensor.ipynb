{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor creation ops\n",
    "https://pytorch.org/docs/1.1.0/torch.html#creation-ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### torch.tensor\n",
    "  \n",
    "constructs a tensor with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor(  \n",
    "    data,  \n",
    "    dtype=None,  \n",
    "    device=None,  \n",
    "    requires_grad=False,  \n",
    "    pin_memory=False)\n",
    "  \n",
    "* **data (array_like)** – Initial data for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types.\n",
    "  \n",
    "  \n",
    "* dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, **infers data type from data**.\n",
    "  \n",
    "  \n",
    "* device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "* **requires_grad** (bool, optional) – If autograd should record operations on the returned tensor. **Default: False**.\n",
    "* pin_memory (bool, optional) – If set, returned tensor would be allocated in the **pinned memory**. **Works only for CPU tensors**. Default: False.  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### always copy 언제나 data 를 복사하여 만든다. 이를 피하려면 아래 방법을 쓰라.\n",
    "`torch.tensor()` **always** copies data.  \n",
    "If you have a **Tensor data** and want to avoid a copy, use `torch.Tensor.requires_grad_()` or `torch.Tensor.detach()`.  \n",
    "If you have a **NumPy ndarray** and want to avoid a copy, use `torch.as_tensor()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor x : pass the data and constructs a leaf variable\n",
    "\n",
    "When data is a **tensor x**, `torch.tensor()` reads out ‘the data’ from whatever it is passed,  \n",
    "and constructs a leaf variable. \n",
    "  \n",
    "  \n",
    "Therefore `torch.tensor(x)` is equivalent to `x.clone().detach()` and  \n",
    "`torch.tensor(x, requires_grad=True)` is equivalent to `x.clone().detach().requires_grad_(True)`.  \n",
    "The equivalents using clone() and detach() are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function tensor:\n",
      "\n",
      "tensor(...)\n",
      "    tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "    \n",
      "    Constructs a tensor with :attr:`data`.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        :func:`torch.tensor` always copies :attr:`data`. If you have a Tensor\n",
      "        ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "        or :func:`torch.Tensor.detach`.\n",
      "        If you have a NumPy ``ndarray`` and want to avoid a copy, use\n",
      "        :func:`torch.as_tensor`.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        When data is a tensor `x`, :func:`torch.tensor` reads out 'the data' from whatever it is passed,\n",
      "        and constructs a leaf variable. Therefore ``torch.tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "        and ``torch.tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "        The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "    \n",
      "    Args:\n",
      "        data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
      "            NumPy ``ndarray``, scalar, and other types.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, infers data type from :attr:`data`.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "        pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "            the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "    \n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
      "        tensor([[ 0.1000,  1.2000],\n",
      "                [ 2.2000,  3.1000],\n",
      "                [ 4.9000,  5.2000]])\n",
      "    \n",
      "        >>> torch.tensor([0, 1])  # Type inference on data\n",
      "        tensor([ 0,  1])\n",
      "    \n",
      "        >>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
      "                         dtype=torch.float64,\n",
      "                         device=torch.device('cuda:0'))  # creates a torch.cuda.DoubleTensor\n",
      "        tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n",
      "    \n",
      "        >>> torch.tensor(3.14159)  # Create a scalar (zero-dimensional tensor)\n",
      "        tensor(3.1416)\n",
      "    \n",
      "        >>> torch.tensor([])  # Create an empty tensor (of size (0,))\n",
      "        tensor([])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. type inference on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 1.2000],\n",
       "        [2.2000, 3.1000],\n",
       "        [4.9000, 5.2000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1111, 0.2222, 0.3333]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
    "                 dtype=torch.float64,\n",
    "                 device=torch.device('cpu:0'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. zero dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1416)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(3.14159)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. empty tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
